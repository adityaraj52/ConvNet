{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.models.image.cifar10 import cifar10_input\n",
    "from tensorflow.models.image.cifar10 import cifar10\n",
    "from six.moves import urllib\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.models.image.cifar10 import cifar10_input\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Global constants describing the CIFAR-10 data set.\n",
    "IMAGE_SIZE = cifar10_input.IMAGE_SIZE\n",
    "cifar10_input.NUM_CLASSES = 2\n",
    "cifar10_input.NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN = 5000\n",
    "cifar10_input.NUM_EXAMPLES_PER_EPOCH_FOR_EVAL = 1000\n",
    "\n",
    "import cifar10\n",
    "import cifar10_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n",
    "# #\n",
    "# # Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# # you may not use this file except in compliance with the License.\n",
    "# # You may obtain a copy of the License at\n",
    "# #\n",
    "# #     http://www.apache.org/licenses/LICENSE-2.0\n",
    "# #\n",
    "# # Unless required by applicable law or agreed to in writing, software\n",
    "# # distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# # See the License for the specific language governing permissions and\n",
    "# # limitations under the License.\n",
    "# # ==============================================================================\n",
    "\n",
    "# \"\"\"A binary to train CIFAR-10 using a single GPU.\n",
    "\n",
    "# Accuracy:\n",
    "# cifar10_train.py achieves ~86% accuracy after 100K steps (256 epochs of\n",
    "# data) as judged by cifar10_eval.py.\n",
    "\n",
    "# Speed: With batch_size 128.\n",
    "\n",
    "# System        | Step Time (sec/batch)  |     Accuracy\n",
    "# ------------------------------------------------------------------\n",
    "# 1 Tesla K20m  | 0.35-0.60              | ~86% at 60K steps  (5 hours)\n",
    "# 1 Tesla K40m  | 0.25-0.35              | ~86% at 100K steps (4 hours)\n",
    "\n",
    "# Usage:\n",
    "# Please see the tutorial and website for how to download the CIFAR-10\n",
    "# data set, compile the program and train the model.\n",
    "\n",
    "# http://tensorflow.org/tutorials/deep_cnn/\n",
    "# \"\"\"\n",
    "\n",
    "# from __future__ import absolute_import\n",
    "# from __future__ import division\n",
    "# from __future__ import print_function\n",
    "# import cifar10\n",
    "\n",
    "# from datetime import datetime\n",
    "# import os.path\n",
    "# import time\n",
    "\n",
    "# import numpy as np\n",
    "# from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "# import tensorflow as tf\n",
    "\n",
    "\n",
    "# train_dir = \"/Users/adityaraj/Documents/Projects/NeuralNetworkAndKaggleCompetition/Resources/BatchFiles/cifar10_train\"\n",
    "# max_steps = 1000\n",
    "# log_device_placement = False\n",
    "# batch_size = 128\n",
    "\n",
    "# def train():\n",
    "#   \"\"\"Train CIFAR-10 for a number of steps.\"\"\"\n",
    "#   with tf.Graph().as_default():\n",
    "#     global_step = tf.Variable(0, trainable=False)\n",
    "\n",
    "#     # Get images and labels for CIFAR-10.\n",
    "#     images, labels = cifar10.distorted_inputs()\n",
    "\n",
    "#     # Build a Graph that computes the logits predictions from the\n",
    "#     # inference model.\n",
    "#     logits = cifar10.inference(images)\n",
    "\n",
    "#     # Calculate loss.\n",
    "#     loss = cifar10.loss(logits, labels)\n",
    "\n",
    "#     # Build a Graph that trains the model with one batch of examples and\n",
    "#     # updates the model parameters.\n",
    "#     train_op = cifar10.train(loss, global_step)\n",
    "\n",
    "#     # Create a saver.\n",
    "#     saver = tf.train.Saver(tf.all_variables())\n",
    "\n",
    "#     # Build the summary operation based on the TF collection of Summaries.\n",
    "#     summary_op = tf.merge_all_summaries()\n",
    "\n",
    "#     # Build an initialization operation to run below.\n",
    "#     init = tf.global_variables_initializer()\n",
    "\n",
    "#     # Start running operations on the Graph.\n",
    "#     sess = tf.Session(config=tf.ConfigProto(\n",
    "#         log_device_placement=log_device_placement))\n",
    "#     sess.run(init)\n",
    "\n",
    "#     # Start the queue runners.\n",
    "#     tf.train.start_queue_runners(sess=sess)\n",
    "\n",
    "#     summary_writer = tf.train.SummaryWriter(train_dir, sess.graph)\n",
    "\n",
    "#     for step in xrange(max_steps):\n",
    "#       start_time = time.time()\n",
    "#       _, loss_value = sess.run([train_op, loss])\n",
    "#       duration = time.time() - start_time\n",
    "\n",
    "#       assert not np.isnan(loss_value), 'Model diverged with loss = NaN'\n",
    "\n",
    "#       if step % 10 == 0:\n",
    "#         num_examples_per_step = batch_size\n",
    "#         examples_per_sec = num_examples_per_step / duration\n",
    "#         sec_per_batch = float(duration)\n",
    "\n",
    "#         format_str = ('%s: step %d, loss = %.2f (%.1f examples/sec; %.3f '\n",
    "#                       'sec/batch)')\n",
    "#         print (format_str % (datetime.now(), step, loss_value,\n",
    "#                              examples_per_sec, sec_per_batch))\n",
    "\n",
    "#       if step % 100 == 0:\n",
    "#         summary_str = sess.run(summary_op)\n",
    "#         summary_writer.add_summary(summary_str, step)\n",
    "\n",
    "#       # Save the model checkpoint periodically.\n",
    "#       if step % 1000 == 0 or (step + 1) == max_steps:\n",
    "#         checkpoint_path = os.path.join(train_dir, 'model.ckpt')\n",
    "#         saver.save(sess, checkpoint_path, global_step=step)\n",
    "\n",
    "\n",
    "# def main(argv=None):  # pylint: disable=unused-argument\n",
    "#   cifar10.maybe_download_and_extract()\n",
    "#   if tf.gfile.Exists(train_dir):\n",
    "#     tf.gfile.DeleteRecursively(train_dir)\n",
    "#   tf.gfile.MakeDirs(train_dir)\n",
    "#   train()\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#   #tf.app.run()\n",
    "#     train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cifar10_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-33d9fd388a4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cifar10_train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cifar10_train' is not defined"
     ]
    }
   ],
   "source": [
    "exec(\"cifar10_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
